name: crappy
team: shitballz
envID: local
appVersion: production-global-19900101.101010-zxc111y
repoName: shitballz-service
#deploymentRunId: kdnkdmck

argoRollouts:
  enabled: true
  activeMetadata:
    labels:
      role: active
  progressiveDelivery:
    enabled: true
    stableMetadata:
      labels:
        role: stable
    canaryMetadata:
      labels:
        role: canary
    blackBox:
      url: http://nexus.frontegg.svc.cluster.local/blackbox
      timeout: 1200
      consecutiveErrorLimit: 0
      failureLimit: 1
      count: 1
      method: POST
      headers:
        - key: Content-Type # if body is a json, it is recommended to set the Content-Type
          value: "application/json"
    steps:
      replicas: 1


image:
  repository: frontegg/crappy-service
  prefix: "1111111111.dkr.ecr.us-east-500.amazonaws.com/docker-hub/"

externalSecret:
  enabled: true
  annotations:
    someting: cool
  mountPath: /etc/config/config.yaml
  text: |
    {{- $secret := .contents | fromYaml }}
    apiKey: {{ $secret.frontegg.apiKeys.logsStreamingServiceApiKey | toYaml }}
    splitIOKey: {{ $secret.externalServices.split.sdkKey | toYaml }}
    kafka:
      brokerList: {{ $secret.databases.kafka.brokerList | toYaml }}
      saslUsername: {{ $secret.databases.kafka.saslUserName | toYaml }}
      saslPassword: {{ $secret.databases.kafka.saslPassword | toYaml }}
    databases:
      mysql:
        host: {{ $secret.databases.generalMysql.host | toYaml }}
        username: {{ $secret.databases.generalMysql.username | toYaml }}
        password: {{ $secret.databases.generalMysql.password | toYaml }}
  data:
    SHIT_FIST_SHIT: '{{ (.contents | fromYaml).shit.fist.shit }}'

configmap:
  annotations:
    something/else: bugger

configuration:
  map:
    config-center:
      ENV_VAR: key-in-config-center

prometheusRule:
  enabled: true

ingresses:
  ingtls:
    enabled: true
    hostname: xxxx.stg.com
    tls:
      enabled: true
      hostname: xxxx.stg.com
      secretName: tls-secret
    service:
      name: someshitttyservice
  tesla:
    enabled: true
    hostname: nicola.tesla
    annotations:
      nginx.ingress.kubernetes.io/server-snippet: |
        location ~* ^/(metrics|health) {
          deny all;
          return 403;
        }
  newton:
    enabled: true
    hostname: isaac.newton
    service:
      name: "frontegg-api-gateway"
  galileo:
    enabled: true
    annotations:
      nginx.ingress.kubernetes.io/server-snippet: |
        location ~* ^/(metrics|health) {
          deny all;
          return 403;
        }
    rules:
      - hostname: galileo.galilei
        paths:
          - path: /galileo
            servicePort: 8080
            pathType: Prefix
          - path: /galilei
      - hostname: alon.wanted.more.hosts
        paths:
          - path: /alon
            servicePort: 8080
            pathType: Prefix
          - path: /smartass
  split:
    enabled: true
    ingressClassName: alb
    hostname: split.stg.backegg.io-{{ .Values.name }}
    service:
      name: '{{ include "web.name" $ }}'
      port: 80
    annotations:
      alb.ingress.kubernetes.io/scheme: internal
      alb.ingress.kubernetes.io/target-type: ip
      alb.ingress.kubernetes.io/group.name: internal.observability
      external-dns.alpha.kubernetes.io/cloudflare-proxied: "false"
    path: /
    pathType: Prefix

web:
  enabled: true
  resources:
    requests:
      cpu: 500m
      memory: 500Mi
  env:
    - name: SOME_WEB_VAR
      value: some_web_value
  additionalVolumes: |
    - name: vol-acl-config
      configMap:
        name: '{{ include "fullname" $ }}-acl-config'
  additionalVolumeMounts: |
    - name: vol-acl-config
      mountPath: /etc/smokescreen/acl.yaml
      subPath: acl.yaml
    - name: vol-acl-config
      mountPath: /etc/smokescreen/config.yaml
      subPath: config.yaml
  service:
    ports:
      - port: 8080
        targetPort: 3050
        protocol: TCP
        name: http
  ports:
    - name: http
      containerPort: 3050
  vars:
    - name: SPICEDB_DATABASE_URL
      valueFrom:
        secretRef:
          name: '{{ include "name" $ }}'
          key: SPICEDB_DATABASE_URL
  podAnnotations:
    some/other: anot
    some/other2: anot2
  labels:
    scrape-for-metrics: enabled
  autoscaling:
    enabled: true
    scaledObject:
      enabled: true
  serviceProfile:
    enabled: true
    routes:
      - condition:
          method: XXXX
          pathRegex: /pathx
        name: GET /pathx
      - condition:
          method: YYYYYY
          pathRegex: /pathy
        name: PUT /pathy
      - condition:
          method: ZZZZZZ
          pathRegex: /pathz
        name: /pathz

hp:
  enabled: true
  image:
    name: shit
    prefix: dumpster/
    tag: latest
  resources:
    requests:
      cpu: 500m
      memory: 500Mi
  env:
    - name: SOME_HP_VAR
      value: some_hp_value
  additionalVolumes: |
    - name: hp-vol
      configMap:
        name: '{{ include "fullname" $ }}-hp'
  additionalVolumeMounts: |
    - name: hp-vol
      mountPath: /etc/smokescreen/acl.yaml
      subPath: acl.yaml
    - name: hp-vol
      mountPath: /etc/smokescreen/config.yaml
      subPath: config.yaml
  service:
    scrape: false
    labels:
      monitoring-metrics: hp
    ports:
      - port: 80
        targetPort: 3000
        name: http
  ports:
    - name: http
      containerPort: 3000
  vars:
    - name: SPICEDB_DATABASE_URL
      valueFrom:
        secretRef:
          name: '{{ include "name" $ }}'
          key: SPICEDB_DATABASE_URL
  podAnnotations:
    some/other: hp
    some/other2: hp2
  autoscaling:
    enabled: true
    scaledObject:
      enabled: true

worker:
  enabled: true
  resources:
    requests:
      cpu: 500m
      memory: 500Mi
  env:
    - name: SOME_WORKER_VAR
      value: some_worker_value
  additionalVolumes: |
    - name: worker-vol
      configMap:
        name: '{{ include "fullname" $ }}-worker'
  additionalVolumeMounts: |
    - name: worker-vol
      mountPath: /etc/smokescreen/acl.yaml
      subPath: acl.yaml
    - name: worker-vol
      mountPath: /etc/smokescreen/config.yaml
      subPath: config.yaml
  service:
    labels:
      monitoring-metrics: worker
    ports:
      - port: 80
        targetPort: 3000
        name: access-port
  labels:
    scrape-for-metrics: enabled
  nodeSelector:
    workload: general
  vars:
    - name: SPICEDB_DATABASE_URL
      valueFrom:
        secretRef:
          name: '{{ include "name" $ }}'
          key: SPICEDB_DATABASE_URL

  ports:
    - name: access-port
      containerPort: 3000
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 4
    targetCPUUtilizationPercentage: 50
    targetMemoryUtilizationPercentage: 75
    scaledObject:
      enabled: true
      annotations:
        something/scaledobject/worker: annotation
      triggers:
        - type: cpu
          metadata:
            type: Utilization
            value: "80"
        - type: memory
          metadata:
            type: Utilization
            value: "75"
        - type: prometheus
          name: kafka time lag
          metadata:
            serverAddress: http://vmselect-vm.observability.svc.cluster.local:8481/select/0/prometheus
            query: max(sum(aws_kafka_estimated_max_time_lag_maximum{dimension_Consumer_Group=~".*api-gateway.*" }) by (dimension_Consumer_Group))
            threshold: "50"
      advanced:
        horizontalPodAutoscalerConfig:
          behavior:
            scaleDown:
              stabilizationWindowSeconds: 300
              policies:
                - type: Pods
                  value: 1
                  periodSeconds: 60
            scaleUp:
              stabilizationWindowSeconds: 0
              policies:
                - type: Pods
                  value: 1
                  periodSeconds: 15
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: workload
                operator: In
                values:
                  - general
                  - '{{ include "worker.name" $ }}-poop'

jobs:
  mgr:
    enabled: true
    metadata:
      annotations:
        helm.sh/hook-weight: "-200"
        something/mgr: someannotation-mgr
    spec:
      annotations: {}
      command: ["/bin/bash"]
      args: ["run-migrations.sh"]
      resources:
        requests:
          cpu: 500m
          memory: 500Mi
  test:
    enabled: true
    spec:
      image: testimage
      command: ["/bin/bash"]
      args: ["test"]
    vars:
      - name: SPICEDB_DATABASE_URL
        valueFrom:
          secretRef:
            name: '{{ include "name" $ }}'
            key: SPICEDB_DATABASE_URL


  test2:
    enabled: true
    metadata:
      annotations:
        shit: test2
    spec:
      command: ["/bin/bash"]
      args: ["test"]
  job-with-vols:
    enabled: true
    metadata:
      annotations:
        shit: test2
    spec:
      command: ["/bin/bash"]
      args: ["test"]
      additionalVolumes: |
        - name: worker-vol
          configMap:
            name: '{{ include "fullname" $ }}-worker'
      additionalVolumeMounts: |
        - name: worker-vol
          mountPath: /etc/smokescreen/acl.yaml
          subPath: acl.yaml
        - name: worker-vol
          mountPath: /etc/smokescreen/config.yaml
          subPath: config.yaml

cronjobs:
  refresh:
    enabled: true
    resources:
      requests:
        cpu: 500m
        memory: 500Mi
    metadata:
      annotations:
        something/cronjob: someannotation
    command: ["/bin/bash"]
    args: ["entrypoint.sh"]
    schedule: "0 * * * *"
    ttlSecondsAfterFinished: 600
    concurrencyPolicy: Replace
    failedJobsHistoryLimit: 1
    successfulJobsHistoryLimit: 1
    restartPolicy: Never
    image: pieceofshit:image
    nodeSelector: {}
    additionalVolumes: |
      - name: worker-vol
        configMap:
          name: '{{ include "fullname" $ }}-worker'
    additionalVolumeMounts: |
      - name: worker-vol
        mountPath: /etc/smokescreen/acl.yaml
        subPath: acl.yaml
      - name: worker-vol
        mountPath: /etc/smokescreen/config.yaml
        subPath: config.yaml
    vars:
      - name: SPICEDB_DATABASE_URL
        valueFrom:
          secretRef:
            name: '{{ include "name" $ }}'
            key: SPICEDB_DATABASE_URL

serviceAccount:
  enabled: true
  annotations:
    someshit/knuckle: enabled

role:
  enabled: true
  kind: ClusterRole
  namespace: ""
  annotations:
    my/cool: annotation
  rules:
    - apiGroups: ["*"]
      resources: ["*"]
      verbs: ["*"]

rolebinding:
  enabled: true
  namespace: ""
  annotations:
    my/cool/rolebinding: annotation
