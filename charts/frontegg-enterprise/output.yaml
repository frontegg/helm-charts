---
# Source: frontegg-enterprise/charts/admins/templates/web/web-pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: admins-v2-web
spec:
  maxUnavailable: 30%
  selector:
    matchLabels:
      app.frontegg.com/name: admins-v2-web
---
# Source: frontegg-enterprise/charts/oauth-service/templates/web/web-pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: oauth-v2-web
spec:
  maxUnavailable: 30%
  selector:
    matchLabels:
      app.frontegg.com/name: oauth-v2-web
---
# Source: frontegg-enterprise/charts/debezium-operator/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/managed-by: quarkus
    app.kubernetes.io/name: debezium-operator
    app.kubernetes.io/version: 3.1.0-final
  name: debezium-operator
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/010-ServiceAccount-strimzi-cluster-operator.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: strimzi-cluster-operator
  namespace: default
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: service-account
    release: xxx
    heritage: Helm
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/050-ConfigMap-strimzi-cluster-operator.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: strimzi-cluster-operator
  namespace: default
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: logging-config-map
    release: xxx
    heritage: Helm
data:
  log4j2.properties: |
    name = COConfig
    monitorInterval = 30

    appender.console.type = Console
    appender.console.name = STDOUT
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n

    rootLogger.level = ${env:STRIMZI_LOG_LEVEL:-INFO}
    rootLogger.appenderRefs = stdout
    rootLogger.appenderRef.console.ref = STDOUT

    # Kafka AdminClient logging is a bit noisy at INFO level
    logger.kafka.name = org.apache.kafka
    logger.kafka.level = WARN

    # Zookeeper is very verbose even on INFO level -> We set it to WARN by default
    logger.zookeepertrustmanager.name = org.apache.zookeeper
    logger.zookeepertrustmanager.level = WARN

    # Keeps separate level for Netty logging -> to not be changed by the root logger
    logger.netty.name = io.netty
    logger.netty.level = INFO
---
# Source: frontegg-enterprise/charts/debezium-operator/templates/debeziumserver-crd-cluster-role.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "ClusterRole"
metadata:
  name: "debeziumserver-cluster-role"
rules:
- apiGroups:
  - "debezium.io"
  resources:
  - "debeziumservers"
  - "debeziumservers/status"
  - "debeziumservers/finalizers"
  verbs:
  - "get"
  - "list"
  - "watch"
  - "patch"
  - "update"
  - "create"
  - "delete"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "rolebindings"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "services"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "persistentvolumeclaims"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "serviceaccounts"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "roles"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "secrets"
  verbs:
  - "get"
  - "list"
  - "watch"
---
# Source: frontegg-enterprise/charts/debezium-operator/templates/generic-crd-cluster-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: debezium-operator-crd-validating-cluster-role
  labels:
    app.kubernetes.io/name: debezium-operator
    app.kubernetes.io/version: 3.1.0-final
    app.kubernetes.io/managed-by: quarkus
rules:
  - apiGroups:
      - apiextensions.k8s.io
    resources:
      - customresourcedefinitions
    verbs:
      - get
      - list
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/020-ClusterRole-strimzi-cluster-operator-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-namespaced
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: role
    release: xxx
    heritage: Helm
rules:
# Resources in this role are used by the operator based on an operand being deployed in some namespace. When needed, you
# can deploy the operator as a cluster-wide operator. But grant the rights listed in this role only on the namespaces
# where the operands will be deployed. That way, you can limit the access the operator has to other namespaces where it
# does not manage any clusters.
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
    # The cluster operator needs to access and manage rolebindings to grant Strimzi components cluster permissions
  - rolebindings
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
    # The cluster operator needs to access and manage roles to grant the entity operator permissions
  - roles
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
    # The cluster operator needs to access and delete pods, this is to allow it to monitor pod health and coordinate rolling updates
  - pods
    # The cluster operator needs to access and manage service accounts to grant Strimzi components cluster permissions
  - serviceaccounts
    # The cluster operator needs to access and manage config maps for Strimzi components configuration
  - configmaps
    # The cluster operator needs to access and manage services and endpoints to expose Strimzi components to network traffic
  - services
  - endpoints
    # The cluster operator needs to access and manage secrets to handle credentials
  - secrets
    # The cluster operator needs to access and manage persistent volume claims to bind them to Strimzi components for persistent data
  - persistentvolumeclaims
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - "apps"
  resources:
    # The cluster operator needs to access and manage deployments to run deployment based Strimzi components
  - deployments
    # The cluster operator needs to access and manage stateful sets to run stateful sets based Strimzi components
  - statefulsets
    # The cluster operator needs to access replica-sets to manage Strimzi components and to determine error states
  - replicasets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - "apps"
  resources:
    # The Cluster Operator needs to scale Deployments while migrating Connect and Mirror Maker 2 clusters from Deployments to StrimziPodSets
  - deployments/scale
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - "events.k8s.io" # new events api, used by cluster operator
  resources:
    # The cluster operator needs to be able to create events
  - events
  verbs:
  - create
- apiGroups:
    # Kafka Connect Build on OpenShift requirement
  - build.openshift.io
  resources:
  - buildconfigs
  - buildconfigs/instantiate
  - builds
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - networking.k8s.io
  resources:
    # The cluster operator needs to access and manage network policies to lock down communication between Strimzi components
  - networkpolicies
    # The cluster operator needs to access and manage ingresses which allow external access to the services in a cluster
  - ingresses
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - route.openshift.io
  resources:
    # The cluster operator needs to access and manage routes to expose Strimzi components for external access
  - routes
  - routes/custom-host
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - image.openshift.io
  resources:
  # The cluster operator needs to verify the image stream when used for Kafka Connect image build
  - imagestreams
  verbs:
  - get
- apiGroups:
  - policy
  resources:
    # The cluster operator needs to access and manage pod disruption budgets this limits the number of concurrent disruptions
    # that a Strimzi component experiences, allowing for higher availability
  - poddisruptionbudgets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/021-ClusterRole-strimzi-cluster-operator-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-global
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: role
    release: xxx
    heritage: Helm
rules:
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
    # The cluster operator needs to create and manage cluster role bindings in the case of an install where a user
    # has specified they want their cluster role bindings generated
  - clusterrolebindings
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - storage.k8s.io
  resources:
    # The cluster operator requires "get" permissions to view storage class details
    # This is because only a persistent volume of a supported storage class type can be resized
  - storageclasses
  verbs:
  - get
- apiGroups:
    - ""
  resources:
    # The cluster operator requires "list" permissions to view all nodes in a cluster
    # The listing is used to determine the node addresses when NodePort access is configured
    # These addresses are then exposed in the custom resource states
  - nodes
  verbs:
  - list
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/022-ClusterRole-strimzi-cluster-operator-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-leader-election
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: role
    release: xxx
    heritage: Helm
rules:
- apiGroups:
  - coordination.k8s.io
  resources:
    # The cluster operator needs to access and manage leases for leader election
    # The "create" verb cannot be used with "resourceNames"
  - leases
  verbs:
  - create
- apiGroups:
  - coordination.k8s.io
  resources:
    # The cluster operator needs to access and manage leases for leader election
  - leases
  resourceNames:
    # The default RBAC files give the operator only access to the Lease resource names strimzi-cluster-operator
    # If you want to use another resource name or resource namespace, you have to configure the RBAC resources accordingly
  - strimzi-cluster-operator
  verbs:
  - get
  - list
  - watch
  - delete
  - patch
  - update
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/023-ClusterRole-strimzi-cluster-operator-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-watched
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: role
    release: xxx
    heritage: Helm
rules:
# Resources in this role are being watched by the operator. When operator is deployed as cluster-wide, these permissions
# need to be granted to the operator on a cluster wide level as well, even if the operands will be deployed only in
# few of the namespaces in given cluster. This is required to set up the Kubernetes watches and informers.
# Note: The rights included in this role might change in the future
- apiGroups:
  - ""
  resources:
    # The cluster operator needs to access and delete pods, this is to allow it to monitor pod health and coordinate rolling updates
  - pods
  verbs:
  - watch
  - list
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  # The Cluster Operator operates the Strimzi custom resources
  - kafkas
  - kafkanodepools
  - kafkaconnects
  - kafkaconnectors
  - kafkamirrormakers
  - kafkabridges
  - kafkamirrormaker2s
  - kafkarebalances
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  # The Cluster Operator needs to manage the status of the Strimzi custom resources
  - kafkas/status
  - kafkanodepools/status
  - kafkaconnects/status
  - kafkaconnectors/status
  - kafkamirrormakers/status
  - kafkabridges/status
  - kafkamirrormaker2s/status
  - kafkarebalances/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - "core.strimzi.io"
  resources:
  # The cluster operator uses StrimziPodSets to manage the Kafka and ZooKeeper pods
  - strimzipodsets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - "core.strimzi.io"
  resources:
  # The Cluster Operator needs to manage the status of the StrimziPodSet custom resource
  - strimzipodsets/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
    - "kafka.strimzi.io"
  resources:
    # The Cluster Operator needs deletion for KafkaRebalance only (during auto-rebalancing)
    - kafkarebalances
  verbs:
    - delete
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/030-ClusterRole-strimzi-kafka-broker.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-kafka-broker
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: broker-role
    release: xxx
    heritage: Helm
rules:
- apiGroups:
  - ""
  resources:
    # The Kafka Brokers require "get" permissions to view the node they are on
    # This information is used to generate a Rack ID that is used for High Availability configurations
  - nodes
  verbs:
  - get
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/031-ClusterRole-strimzi-entity-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-entity-operator
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: entity-operator-role
    release: xxx
    heritage: Helm
rules:
- apiGroups:
  - "kafka.strimzi.io"
  resources:
    # The Entity Operator contains the Topic Operator which needs to access and manage KafkaTopic resources
  - kafkatopics
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
  - delete
- apiGroups:
  - "kafka.strimzi.io"
  resources:
    # The Entity Operator contains the User Operator which needs to access and manage KafkaUser resources
  - kafkausers
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
- apiGroups:
  - "kafka.strimzi.io"
  resources:
    # The Entity Operator contains the Topic Operator which needs to access and manage KafkaTopic resources
  - kafkatopics/status
    # The Entity Operator contains the User Operator which needs to access and manage KafkaUser resources
  - kafkausers/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - ""
  resources:
    # The entity operator user-operator needs to access and manage secrets to store generated credentials
  - secrets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/033-ClusterRole-strimzi-kafka-client.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-kafka-client
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: client-role
    release: xxx
    heritage: Helm
rules:
- apiGroups:
  - ""
  resources:
    # The Kafka clients (Connect, Mirror Maker, etc.) require "get" permissions to view the node they are on
    # This information is used to generate a Rack ID (client.rack option) that is used for consuming from the closest
    # replicas when enabled
  - nodes
  verbs:
  - get
---
# Source: frontegg-enterprise/charts/debezium-operator/templates/debeziumserver-crd-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: debeziumserver-role-binding
  labels:
    app.kubernetes.io/name: debezium-operator
    app.kubernetes.io/version: 3.1.0-final
    app.kubernetes.io/managed-by: quarkus
roleRef:
  kind: ClusterRole
  apiGroup: rbac.authorization.k8s.io
  name: debeziumserver-cluster-role
subjects:
  - kind: ServiceAccount
    name: debezium-operator
    namespace: default
---
# Source: frontegg-enterprise/charts/debezium-operator/templates/generic-crd-cluster-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: debezium-operator-crd-validating-role-binding
  labels:
    app.kubernetes.io/name: debezium-operator
    app.kubernetes.io/version: 3.1.0-final
    app.kubernetes.io/managed-by: quarkus
roleRef:
  kind: ClusterRole
  apiGroup: rbac.authorization.k8s.io
  name: debezium-operator-crd-validating-cluster-role
subjects:
  - kind: ServiceAccount
    name: debezium-operator
    namespace: default
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/021-ClusterRoleBinding-strimzi-cluster-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: role-binding
    release: xxx
    heritage: Helm
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-global
  apiGroup: rbac.authorization.k8s.io
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator-kafka-broker-delegation
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: broker-role-binding
    release: xxx
    heritage: Helm
# The Kafka broker cluster role must be bound to the cluster operator service account so that it can delegate the cluster role to the Kafka brokers.
# This must be done to avoid escalating privileges which would be blocked by Kubernetes.
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-kafka-broker
  apiGroup: rbac.authorization.k8s.io
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator-kafka-client-delegation
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: client-role-binding
    release: xxx
    heritage: Helm
# The Kafka clients cluster role must be bound to the cluster operator service account so that it can delegate the
# cluster role to the Kafka clients using it for consuming from closest replica.
# This must be done to avoid escalating privileges which would be blocked by Kubernetes.
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-kafka-client
  apiGroup: rbac.authorization.k8s.io
---
# Source: frontegg-enterprise/templates/kafka-connect/debezium-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: connector-configuration-role
  namespace: default
rules:
- apiGroups: [""]
  resources: ["secrets"]
  resourceNames: ["identity-mysql-credentials"] #change to secret name to variable
  verbs: ["get"]
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/020-RoleBinding-strimzi-cluster-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator
  namespace: default
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: role-binding
    release: xxx
    heritage: Helm
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-namespaced
  apiGroup: rbac.authorization.k8s.io
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/022-RoleBinding-strimzi-cluster-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator-leader-election
  namespace: default
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: role-binding
    release: xxx
    heritage: Helm
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-leader-election
  apiGroup: rbac.authorization.k8s.io
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/023-RoleBinding-strimzi-cluster-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator-watched
  namespace: default
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: role-binding
    release: xxx
    heritage: Helm
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-watched
  apiGroup: rbac.authorization.k8s.io
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator-entity-operator-delegation
  namespace: default
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: entity-operator-role-binding
    release: xxx
    heritage: Helm
# The Entity Operator cluster role must be bound to the cluster operator service account so that it can delegate the cluster role to the Entity Operator.
# This must be done to avoid escalating privileges which would be blocked by Kubernetes.
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-entity-operator
  apiGroup: rbac.authorization.k8s.io
---
# Source: frontegg-enterprise/templates/kafka-connect/connector-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: connector-configuration-role-binding
  namespace: default
subjects:
  - kind: ServiceAccount
    name: debezium-connect-cluster-connect
    namespace: default
roleRef:
  kind: Role
  name: connector-configuration-role
  apiGroup: rbac.authorization.k8s.io
---
# Source: frontegg-enterprise/charts/admins/templates/web/web-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: admins-v2-web
  labels:
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "0b5b99d"
    app.frontegg.com/name: admins-v2-web
    monitoring-metrics: enabled
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 3004
      protocol: TCP
      name: http
  selector:
    app.frontegg.com/name: admins-v2-web
---
# Source: frontegg-enterprise/charts/debezium-operator/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/name: debezium-operator
    app.kubernetes.io/version: 3.1.0-final
    app.kubernetes.io/managed-by: quarkus
  name: debezium-operator
spec:
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 8080
  selector:
    app.kubernetes.io/name: debezium-operator
    app.kubernetes.io/version: 3.1.0-final
  type: ClusterIP
---
# Source: frontegg-enterprise/charts/oauth-service/templates/web/web-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: oauth-v2-web
  labels:
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "adb9c44"
    app.frontegg.com/name: oauth-v2-web
    monitoring-metrics: enabled
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 3018
      protocol: TCP
      name: access-port
  selector:
    app.frontegg.com/name: oauth-v2-web
---
# Source: frontegg-enterprise/charts/admins/templates/web/web-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: admins-v2-web
  labels:
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "0b5b99d"
    app.frontegg.com/name: admins-v2-web
spec:
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      app.frontegg.com/name: admins-v2-web
  template:
    metadata:
      labels:
        app.frontegg.com/team: frontegg
        app.frontegg.com/appVersion: "0b5b99d"
        app.frontegg.com/name: admins-v2-web
      annotations:
        checksum/secret: c0e20220fff95520aeba60c40779d532afa1b44a3db29cb127fab75a69db8da7
        
    spec:
      serviceAccountName: admins-v2
      terminationGracePeriodSeconds: 30
      imagePullSecrets:
        - name: regcred
      volumes:
        - name: secret-volume
          secret:
            secretName: admins-v2
      containers:
        - name: admins
          image: "527305576865.dkr.ecr.us-east-1.amazonaws.com/docker-hub/frontegg/admins-service:0b5b99d"
          imagePullPolicy: Always
          volumeMounts:
            - name: secret-volume
              mountPath: /etc/config/config.env
              subPath: config
          ports:
            - containerPort: 3004
              name: http
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 20
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 5
            periodSeconds: 5
          env:            
            - name: FRONTEGG_IDENTITY_SERVICE_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: identity-service-url
            - name: FRONTEGG_TENANTS_SERVICE_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: tenants-service-url
            - name: FRONTEGG_VENDORS_SERVICE_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: vendors-service-url
            - name: PORTAL_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: portal-url
          envFrom:
            - configMapRef:
                name: admins-v2
          resources:
            limits:
              memory: 1Gi
            requests:
              cpu: 500m
              memory: 1Gi
          command:
            - "/bin/bash"
          args:
            - "entrypoint.sh"
---
# Source: frontegg-enterprise/charts/debezium-operator/templates/deployment.yaml
apiVersion: "apps/v1"
kind: "Deployment"
metadata:
  annotations:
    app.quarkus.io/quarkus-version: "3.17.0"
  labels:
    app.kubernetes.io/name: "debezium-operator"
    app.kubernetes.io/managed-by: "quarkus"
  name: "debezium-operator"
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: "debezium-operator"
  template:
    metadata:
      annotations:
        app.quarkus.io/quarkus-version: "3.17.0"
      labels:
        app.kubernetes.io/managed-by: "quarkus"
        app.kubernetes.io/name: "debezium-operator"
    spec:
      containers:
      - env:
        - name: "KUBERNETES_NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: "QUARKUS_OPERATOR_SDK_CONTROLLERS_DEBEZIUMSERVER_NAMESPACES"
          value: JOSDK_ALL_NAMESPACES
        image: quay.io/debezium/operator:3.1.0.Final
        imagePullPolicy: "Always"
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: "/q/health/live"
            port: 8080
            scheme: "HTTP"
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 10
        name: "debezium-operator"
        ports:
        - containerPort: 8080
          name: "http"
          protocol: "TCP"
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: "/q/health/ready"
            port: 8080
            scheme: "HTTP"
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 10
        startupProbe:
          failureThreshold: 3
          httpGet:
            path: "/q/health/started"
            port: 8080
            scheme: "HTTP"
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 10
      serviceAccountName: "debezium-operator"
---
# Source: frontegg-enterprise/charts/oauth-service/templates/web/web-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: oauth-v2-web
  labels:
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "adb9c44"
    app.frontegg.com/name: oauth-v2-web
spec:
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      app.frontegg.com/name: oauth-v2-web
  template:
    metadata:
      labels:
        app.frontegg.com/team: frontegg
        app.frontegg.com/appVersion: "adb9c44"
        app.frontegg.com/name: oauth-v2-web
      annotations:
        checksum/secret: c93ce7586e0914a15589ec0c9c85f62421840ccdca542c7c4872b1ab73bcd8c0
        
    spec:
      serviceAccountName: oauth-v2
      terminationGracePeriodSeconds: 60
      imagePullSecrets:
        - name: regcred
      volumes:
        - name: secret-volume
          secret:
            secretName: oauth-v2
      containers:
        - name: oauth
          image: "527305576865.dkr.ecr.us-east-1.amazonaws.com/docker-hub/frontegg/oauth-service:adb9c44"
          imagePullPolicy: Always
          volumeMounts:
            - name: secret-volume
              mountPath: /etc/config/config.yaml
              subPath: config
          ports:
            - containerPort: 3018
              name: access-port
          livenessProbe:
            httpGet:
              path: /health
              port: access-port
            initialDelaySeconds: 40
            periodSeconds: 20
          readinessProbe:
            failureThreshold: 1
            httpGet:
              path: /health
              port: access-port
            initialDelaySeconds: 40
            periodSeconds: 5
          env:            
            - name: FRONTEGG_API_GATEWAY_INTERNAL_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: api-gateway-internal-url
            - name: FRONTEGG_API_GATEWAY_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: api-gateway-url
            - name: FRONTEGG_APPLICATIONS_SERVICE_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: applications-service-url
            - name: FRONTEGG_CDN_BUCKET
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: cdn-bucket
            - name: FRONTEGG_ENV_ID
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: env-id
            - name: FRONTEGG_IDENTITY_SERVICE_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: identity-p1-service-url
            - name: FRONTEGG_JAEGER_ENDPOINT
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: tracing-collector-endpoint
            - name: FRONTEGG_OAUTH_SERVICE_DB_NAME
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: oauth-service-db-name
            - name: FRONTEGG_OAUTH_SERVICE_REDIS_DB_INDEX
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: oauth-service-redis-db-index
            - name: FRONTEGG_TEAM_MANAGEMENT_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: team-service-url
            - name: FRONTEGG_TENANTS_SERVICE_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: tenants-service-url
            - name: FRONTEGG_VENDORS_DOMAIN
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: vendors-service-vendors-domain
            - name: FRONTEGG_VENDORS_SERVICE_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: vendors-service-url
          envFrom:
            - configMapRef:
                name: oauth-v2
          resources:
            limits:
              memory: 1Gi
            requests:
              cpu: 750m
              memory: 1Gi
          command:
            - "/bin/bash"
          args:
            - "entrypoint.sh"
---
# Source: frontegg-enterprise/charts/strimzi-kafka-operator/templates/060-Deployment-strimzi-cluster-operator.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: strimzi-cluster-operator
  namespace: default
  labels:
    app: strimzi
    chart: strimzi-kafka-operator-0.45.0
    component: deployment
    release: xxx
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      name: strimzi-cluster-operator
      strimzi.io/kind: cluster-operator
  template:
    metadata:
      labels:
        name: strimzi-cluster-operator
        strimzi.io/kind: cluster-operator
    spec:
      serviceAccountName: strimzi-cluster-operator
      volumes:
        - name: strimzi-tmp
          emptyDir:
            medium: Memory
            sizeLimit: 1Mi
        - name: co-config-volume
          configMap:
            name: strimzi-cluster-operator
      containers:
        - name: strimzi-cluster-operator
          image: quay.io/strimzi/operator:0.45.0
          ports:
            - containerPort: 8080
              name: http
          args:
            - /opt/strimzi/bin/cluster_operator_run.sh
          volumeMounts:
            - name: strimzi-tmp
              mountPath: /tmp
            - name: co-config-volume
              mountPath: /opt/strimzi/custom-config/
          env:
            - name: STRIMZI_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: STRIMZI_FULL_RECONCILIATION_INTERVAL_MS
              value: "120000"
            - name: STRIMZI_OPERATION_TIMEOUT_MS
              value: "300000"
            - name: STRIMZI_DEFAULT_KAFKA_EXPORTER_IMAGE
              value: quay.io/strimzi/kafka:0.45.0-kafka-3.9.0
            - name: STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE
              value: quay.io/strimzi/kafka:0.45.0-kafka-3.9.0
            - name: STRIMZI_KAFKA_IMAGES
              value: |                 
                3.8.0=quay.io/strimzi/kafka:0.45.0-kafka-3.8.0
                3.8.1=quay.io/strimzi/kafka:0.45.0-kafka-3.8.1
                3.9.0=quay.io/strimzi/kafka:0.45.0-kafka-3.9.0
            - name: STRIMZI_KAFKA_CONNECT_IMAGES
              value: |                 
                3.8.0=quay.io/strimzi/kafka:0.45.0-kafka-3.8.0
                3.8.1=quay.io/strimzi/kafka:0.45.0-kafka-3.8.1
                3.9.0=quay.io/strimzi/kafka:0.45.0-kafka-3.9.0
            - name: STRIMZI_KAFKA_MIRROR_MAKER_IMAGES
              value: |                 
                3.8.0=quay.io/strimzi/kafka:0.45.0-kafka-3.8.0
                3.8.1=quay.io/strimzi/kafka:0.45.0-kafka-3.8.1
                3.9.0=quay.io/strimzi/kafka:0.45.0-kafka-3.9.0
            - name: STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES
              value: |                 
                3.8.0=quay.io/strimzi/kafka:0.45.0-kafka-3.8.0
                3.8.1=quay.io/strimzi/kafka:0.45.0-kafka-3.8.1
                3.9.0=quay.io/strimzi/kafka:0.45.0-kafka-3.9.0
            - name: STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE
              value: quay.io/strimzi/operator:0.45.0
            - name: STRIMZI_DEFAULT_USER_OPERATOR_IMAGE
              value: quay.io/strimzi/operator:0.45.0
            - name: STRIMZI_DEFAULT_KAFKA_INIT_IMAGE
              value: quay.io/strimzi/operator:0.45.0
            - name: STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE
              value: quay.io/strimzi/kafka-bridge:0.31.1
            - name: STRIMZI_DEFAULT_KANIKO_EXECUTOR_IMAGE
              value: quay.io/strimzi/kaniko-executor:0.45.0
            - name: STRIMZI_DEFAULT_MAVEN_BUILDER
              value: quay.io/strimzi/maven-builder:0.45.0
            - name: STRIMZI_OPERATOR_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            
            - name: STRIMZI_FEATURE_GATES
              value: ""
            - name: STRIMZI_LEADER_ELECTION_ENABLED
              value: "true"
            - name: STRIMZI_LEADER_ELECTION_LEASE_NAME
              value: "strimzi-cluster-operator"
            - name: STRIMZI_LEADER_ELECTION_LEASE_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: STRIMZI_LEADER_ELECTION_IDENTITY
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          livenessProbe:
            httpGet:
              path: /healthy
              port: http
            initialDelaySeconds: 10
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /ready
              port: http
            initialDelaySeconds: 10
            periodSeconds: 30
          resources:
            limits:
              cpu: 1000m
              memory: 384Mi
            requests:
              cpu: 200m
              memory: 384Mi
---
# Source: frontegg-enterprise/charts/admins/templates/web/web-hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: admins-v2-web
  labels:
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "0b5b99d"
    app.frontegg.com/name: admins-v2-web
  annotations:
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: admins-v2-web
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 50
---
# Source: frontegg-enterprise/charts/oauth-service/templates/web/web-hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: oauth-v2-web
  labels:
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "adb9c44"
    app.frontegg.com/name: oauth-v2-web
  annotations:
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: oauth-v2-web
  minReplicas: 2
  maxReplicas: 2
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 75
---
# Source: frontegg-enterprise/templates/kafka-connect/debezium-connect.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnect
metadata:
  name: debezium-connect-cluster
  annotations:
    strimzi.io/use-connector-resources: "true"
spec:
  version: 3.8.0
  image: 527305576865.dkr.ecr.us-east-1.amazonaws.com/docker-hub/frontegg/kafka-connect:1.0.1
  replicas: 1
  bootstrapServers: b-3.prodmsk360.u4vegd.c12.kafka.us-east-1.amazonaws.com:9092,b-1.prodmsk360.u4vegd.c12.kafka.us-east-1.amazonaws.com:9092,b-2.prodmsk360.u4vegd.c12.kafka.us-east-1.amazonaws.com:9092
  config:
    config.providers: secrets
    config.providers.secrets.class: io.strimzi.kafka.KubernetesSecretConfigProvider
    group.id: connect-cluster
    offset.storage.topic: connect-cluster-offsets
    config.storage.topic: connect-cluster-configs
    status.storage.topic: connect-cluster-status
    # -1 means it will use the default replication factor configured in the broker
    config.storage.replication.factor: -1
    offset.storage.replication.factor: -1
    status.storage.replication.factor: -1
---
# Source: frontegg-enterprise/templates/kafka-connect/debezium-mysql-connector.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  name: debezium-connector-mysql
  labels:
    strimzi.io/cluster: debezium-connect-cluster
spec:
  class: io.debezium.connector.mysql.MySqlConnector
  tasksMax: 1
  config:
    database.hostname: ${secrets:default/identity-mysql-credentials:host}
    database.port: 3306
    database.user: ${secrets:default/identity-mysql-credentials:username}
    database.password: ${secrets:default/identity-mysql-credentials:password}
    snapshot.locking.mode: none
    message.key.columns: frontegg_identity.users_tenants:vendorId,tenantId,userId;frontegg_identity.users:vendorId,email
    transforms.unwrap.delete.handling.mode: rewrite
    tasks.max: 1
    database.history.kafka.topic: dbhistory.identity
    transforms: unwrap
    include.schema.changes: true
    tombstones.on.delete: false
    topic.prefix: identity
    transforms.unwrap.type: io.debezium.transforms.ExtractNewRecordState
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter: org.apache.kafka.connect.json.JsonConverter
    database.allowPublicKeyRetrieval: true
    database.server.id: 184051
    database.history.kafka.bootstrap.servers: b-3.prodmsk360.u4vegd.c12.kafka.us-east-1.amazonaws.com:9092,b-1.prodmsk360.u4vegd.c12.kafka.us-east-1.amazonaws.com:9092,b-2.prodmsk360.u4vegd.c12.kafka.us-east-1.amazonaws.com:9092
    database.server.name: identity
    ransforms.unwrap.drop.tombstones: false
    key.converter.schemas.enable: false
    value.converter.schemas.enable: false
    transforms.unwrap.add.fields: op,table,source.ts_ms
    table.include.list: frontegg_identity.users,frontegg_identity.users_tenants,frontegg_identity.users_tenants_roles,frontegg_identity.roles
    database.include.list: frontegg_identity
    snapshot.mode: schema_only
---
# Source: frontegg-enterprise/charts/admins/templates/rbac/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admins-v2
  labels:
    helm.sh/chart: unified-chart-4.0.100
    app.frontegg.io/version: "4.0.100"
    app.frontegg.io/managed-by: Helm
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "0b5b99d"
  annotations:
    argocd.argoproj.io/sync-wave: "-100"
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-weight: "-100"
---
# Source: frontegg-enterprise/charts/oauth-service/templates/rbac/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: oauth-v2
  labels:
    helm.sh/chart: unified-chart-4.0.100
    app.frontegg.io/version: "4.0.100"
    app.frontegg.io/managed-by: Helm
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "adb9c44"
  annotations:
    argocd.argoproj.io/sync-wave: "-100"
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-weight: "-100"
---
# Source: frontegg-enterprise/charts/admins/templates/config-map.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/sync-options: Force=true,Replace=true
    argocd.argoproj.io/sync-wave: "-100"
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-delete-policy: before-hook-creation
    helm.sh/hook-weight: "-100"
  name: admins-v2
  labels:
    helm.sh/chart: unified-chart-4.0.100
    app.frontegg.io/version: "4.0.100"
    app.frontegg.io/managed-by: Helm
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "0b5b99d"
data:
  CLOUD_ENVIRONMENT: "production"
  FRONTEGG_CONFIG_FILE_PATH: "/etc/config/config.env"
  NODE_ENV: "production"
  name: "admins-v2"
---
# Source: frontegg-enterprise/charts/oauth-service/templates/config-map.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/sync-options: Force=true,Replace=true
    argocd.argoproj.io/sync-wave: "-100"
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-delete-policy: before-hook-creation
    helm.sh/hook-weight: "-100"
  name: oauth-v2
  labels:
    helm.sh/chart: unified-chart-4.0.100
    app.frontegg.io/version: "4.0.100"
    app.frontegg.io/managed-by: Helm
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "adb9c44"
data:
  CLOUD_ENVIRONMENT: "dev"
  FRONTEGG_CDN_URL: "http://localhost:3001"
  FRONTEGG_CONFIG_DIRECTORY: "/etc/config"
  FRONTEGG_JAEGER_ENABLED: "true"
  FRONTEGG_OAUTH_SESSION_TIMEOUT: "86400"
  FRONTEGG_SERVICE_NAME: "oauth-service"
  FRONTEGG_SPLIT_IO_USE_SYNCHRONIZER: "false"
  LOG_LEVEL: "verbose"
  NODE_ENV: "production"
  SENTRY_ENABLED: "false"
  name: "oauth-v2"
---
# Source: frontegg-enterprise/templates/config-center.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-center
  labels:
    helm.sh/chart: frontegg-enterprise-0.0.1
    app.frontegg.com/name: frontegg-enterprise
    app.frontegg.com/instance: xxx
    app.frontegg.io/version: "0.0.1"
    app.frontegg.io/managed-by: Helm
  annotations:
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-weight: "-100"

data:
  prehook-service-url: "http://frontegg-prehook-service"
  admins-service-url: "http://frontegg-admins-service"
  audits-service-url: "http://frontegg-audits-service"
  authentication-service-url: "http://frontegg-authentication-service"
  metadata-service-url: "http://frontegg-metadata-service"
  notification-service-url: "http://frontegg-notification-service"
  reports-engine-url: "http://frontegg-reporting-engine"
  reports-service-url: "http://frontegg-reporting-service"
  team-service-url: "http://frontegg-team-management-service"
  vendors-service-url: "http://frontegg-vendors-service"
  tenants-service-url: "http://frontegg-tenants-service"
  webpush-service-url: "http://frontegg-webpush-service"
  webhook-service-url: "http://frontegg-webhook-service"
  events-service-url: "http://frontegg-event-service"
  identity-service-url: "http://frontegg-identity-service"
  nlp-execution-assistant-url: "http://nlp-execution-assistant-v2-web"
  identity-p1-service-url: "http://frontegg-identity-service-hp"
  integrations-service-url: "http://frontegg-integrations-service"
  api-gateway-url: "https://dev-api.frontegg.com"
  api-gateway-internal-url: "http://api-gateway-v2-web"
  oauth-service-url: "http://frontegg-oauth-service"
  subscriptions-service-url: "http://frontegg-subscriptions-service"
  usage-tracking-service-url: "http://usage-tracking-service"
  env-duplicator-service-url: "http://frontegg-env-duplicator-service"
  policy-service-url: "http://frontegg-policy-service"
  dashboard-env-builder-url: "http://frontegg-dashboard-env-builder-service"
  frontegg-vendor-host: "EMPTY"
  cdn-url: ""
  backoffice-service-url: "http://frontegg-backoffice-service"
  pricing-views-url: "http://frontegg-pricing-views-service"
  email-service-url: "http://frontegg-email-service"
  directory-service-url: "http://frontegg-directory-service"
  logs-service-url: "http://frontegg-logs-service"
  logs-streaming-service-url: "http://frontegg-logs-streaming-service"
  entitlements-service-url: "http://frontegg-entitlements-service"
  security-engines-url: "http://frontegg-security-engines"
  applications-service-url: "http://frontegg-applications-service"
  signals-service-url: "http://frontegg-signals-service"
  security-center-service-url: "http://frontegg-security-center-service"
  custom-code-service-url: "http://frontegg-custom-code-service"
  entitlements-agent-url: "http://frontegg-entitlements-agent"
  auth-hub-service-url: "http://auth-hub-v2-web"
  anomaly-detection-url: "http://anomaly-detection-v2-web"
  idgw-backend-url: ""
  mcp-server-url: ""
  aws-region: "us-east-1"
  policy-service-aws-region: "us-east-1"
  policy-service-s3-opa-policy-bucket: ""
  entitlements-service-s3-opa-policy-bucket: ""
  custom-code-service-lambda-management-role-arn: ""
  custom-code-service-lambda-execution-role-arn: ""
  custom-code-service-lambda-execution-default-policies: ""
  custom-code-service-lambda-layers: ""
  custom-code-service-lambda-env-cx-domain: ""
  env-id: ""
  portal-url: ""
  portal-v1-url: ""
  cors-origin: ""
  custom-domain-cloudflare-ssl-endpoint: ""
  tracing-collector-endpoint: http://logzio-otel-traces.observability.svc.cluster.local:14268/api/traces
  idgw-application-id: ""
  splitio-proxy-endpoint: http://split-proxy-v2-web.feature-management.svc.cluster.local
  audits-topic-name: "audits-v1"
  audits-db-type: "mysql"
  audits-db-name: "frontegg_audits"
  metadata-service-fetch-pubsub-strategy: "true"
  metadata-service-topic-name: "METADATA_UPDATED"
  audits-service-redis-db-index: "2"
  audits-kafka-retry-count: "3"
  authentication-cookie-domain: ""
  authentication-secured-cookie: ""
  api-gateway-enable-redis-store: ""
  api-gateway-usage-reporting-enabled: ""
  api-gateway-metrics-enabled: ""
  api-gateway-redis-db-index: "9"
  enable-multi-hosts: ""
  api-gateway-ignore-hosts: ""
  api-gateway-redirect-enabled: "false"
  api-gateway-redirect-url: ""
  backoffice-redis-db-index: "12"
  entitlements-redis-db-index: "12"
  entitlements-vendor-snapshot-job-delay-ms: "10000"
  entitlements-vendor-snapshot-job-attempts: "3"
  entitlements-service-legacy-vendors-plan-ids: ""
  connectors-worker-service-redis-db-index: "5"
  mixpanel-id: ""
  dashboard-hubspot-enabled: ""
  dashboard-devrev-enabled: "true"
  devrev-api-url: "https://api.devrev.ai"
  dashboard-domain-suffix: ""
  dashboard-cdn-url: ""
  cdn-bucket: "dashboard-static-content-ebdiwxwk"
  backoffice-viewer-role-id: ""
  backoffice-editor-role-id: ""
  frontegg-ui-events-url: "https://ui-events.frontegg.com"
  env-duplicator-mysql-db-name: "frontegg_env_duplicator"
  env-duplicator-configuration-copy-result-topic-name: "configuration-copy-result-v1"
  env-duplicator-configuration-copy-topic-name: "configuration-copy-v1"
  events-service-redis-db-index: "7"
  identity-service-db-name: "frontegg_identity"
  identity-service-audit-triggered-topic-name: "AUDIT_TRIGGERED"
  identity-service-max-concurrent-sessions: "100"
  metadata-service-db-connection-timeout-ms: "30000"
  metadata-service-db-connection-retry-attempts: "3"
  metadata-service-db-connection-retry-delay: "1000"
  metadata-service-ip-stack-url: "http://api.ipstack.com"
  metadata-service-redis-db-index: "0"
  events-pubsub-topic: "events"
  oauth-service-db-name: "frontegg_oauth"
  oauth-service-redis-db-index: "10"
  team-management-service-db-name: "frontegg_team_management"
  team-management-service-vault-url: "" ### check this
  team-management-service-redis-db-index: "1"
  team-management-service-authorization-topic-name: "authorization-v1"
  tenants-usage-reporting-topic-name: "usage-reporting-v1"
  tenants-redis-db-index: "8"
  tenants-service-mysql-db-name: "frontegg_tenants"
  tenant-assets-s3-url: "https://-tenants-assets.s3.us-east-1.amazonaws.com"
  tenant-assets-s3-bucket: ""
  tenant-assets-s3-endpoint: ""
  tenant-assets-s3-aws-endpoint: ""
  vendors-mysql-db-name: "frontegg_vendors"
  vendors-asset-blob-storage-container-name: "public-vendor-assets"
  vendors-service-vendors-domain: "dev.frontegg.com"
  custom-domain-cluster-ingress-class: "nginx"
  custom-domain-cluster-issuer-name: "letsencrypt"
  custom-domain-cluster-default-port: "443"
  custom-domain-cluste-namespace: "custom-domains"
  custom-domain-ssl-endpoint: ""
  custom-domain-cloudflare-transform-rule-set-id: "xxxx"
  custom-domain-cloudflare-origin-rule-set-id: "xxxx"
  vendors-service-kafka-vendors-topic: "vendors-v1"
  webhook-service-mongodb-connection-retry-attempts: "3"
  webhook-service-mongodb-connection-retry-delay: "1000"
  webhook-mysql-db-name: "frontegg_webhooks"
  webhook-proxy-enabled: "true"
  frontegg-proxy-host: "frontegg-forward-proxy"
  frontegg-proxy-port: "8080"
  frontegg-proxy-protocol: "http"

  # TODO: add secret '$secret.frontegg.forwardProxy.auth.password'
---
# Source: frontegg-enterprise/templates/initdb-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: xxx-frontegg-enterprise-initdb-scripts
  namespace: default
  labels:
    helm.sh/chart: frontegg-enterprise-0.0.1
    app.kubernetes.io/name: frontegg-enterprise
    app.kubernetes.io/instance: xxx
    app.kubernetes.io/version: "2025.04.01"
    app.kubernetes.io/managed-by: Helm
  annotations:
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-weight: "-15"
    helm.sh/hook-delete-policy: before-hook-creation
data:
  db.sql: |-
    CREATE DATABASE IF NOT EXISTS frontegg_vendors CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_subscriptions CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_audits CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_events CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_team_management CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_webhooks CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_identity CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_oauth CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_tenants CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_backoffice CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_dashboard_env_builder CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_env_duplicator CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_event_retry CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_entitlements CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
    CREATE DATABASE IF NOT EXISTS frontegg_security_engines CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
---
# Source: frontegg-enterprise/charts/oauth-service/templates/jobs.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: oauth-v2-migrate
  labels:
    app.frontegg.com/name: oauth-v2-job
    app.frontegg.com/instance: xxx
    app.kubernetes.io/component: migrate
  annotations:
    argocd.argoproj.io/sync-options: Force=true,Replace=true
    argocd.argoproj.io/sync-wave: "-10"
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-delete-policy: hook-succeeded,before-hook-creation
    helm.sh/hook-weight: "-5"
spec:
  ttlSecondsAfterFinished: 6000
  completions: 1
  parallelism: 1
  backoffLimit: 1
  podReplacementPolicy: Failed
  template:
    metadata:
      name: oauth-v2-migrate-adb9c44
      labels:
        app.frontegg.com/name: oauth-v2-job
        app.frontegg.com/instance: xxx
        app.kubernetes.io/component: migrate
    spec:
      serviceAccountName: oauth-v2
      restartPolicy: Never
      imagePullSecrets :
        - name: regcred
      volumes:
        - name: secret-volume
          secret:
            secretName: oauth-v2
      containers:
        - name: oauth
          image: "527305576865.dkr.ecr.us-east-1.amazonaws.com/docker-hub/frontegg/oauth-service:adb9c44"
          volumeMounts:
            - name: secret-volume
              mountPath: /etc/config/config.yaml
              subPath: config
          env:            
            - name: FRONTEGG_API_GATEWAY_INTERNAL_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: api-gateway-internal-url
            - name: FRONTEGG_API_GATEWAY_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: api-gateway-url
            - name: FRONTEGG_APPLICATIONS_SERVICE_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: applications-service-url
            - name: FRONTEGG_CDN_BUCKET
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: cdn-bucket
            - name: FRONTEGG_ENV_ID
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: env-id
            - name: FRONTEGG_IDENTITY_SERVICE_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: identity-p1-service-url
            - name: FRONTEGG_JAEGER_ENDPOINT
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: tracing-collector-endpoint
            - name: FRONTEGG_OAUTH_SERVICE_DB_NAME
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: oauth-service-db-name
            - name: FRONTEGG_OAUTH_SERVICE_REDIS_DB_INDEX
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: oauth-service-redis-db-index
            - name: FRONTEGG_TEAM_MANAGEMENT_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: team-service-url
            - name: FRONTEGG_TENANTS_SERVICE_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: tenants-service-url
            - name: FRONTEGG_VENDORS_DOMAIN
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: vendors-service-vendors-domain
            - name: FRONTEGG_VENDORS_SERVICE_URL
              valueFrom:
                configMapKeyRef:
                  name: config-center
                  key: vendors-service-url
          envFrom:
            - configMapRef:
                name: oauth-v2
          command:
            - "/bin/bash"
          args:
            - "run-migrations.sh"
          resources:
            requests:
              cpu: 500m
              memory: 500Mi
---
# Source: frontegg-enterprise/templates/initdb-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: xxx-frontegg-enterprise-initdb
  namespace: default
  labels:
    helm.sh/chart: frontegg-enterprise-0.0.1
    app.kubernetes.io/name: frontegg-enterprise
    app.kubernetes.io/instance: xxx
    app.kubernetes.io/version: "2025.04.01"
    app.kubernetes.io/managed-by: Helm
  annotations:
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-weight: "-10"
    helm.sh/hook-delete-policy: hook-succeeded, before-hook-creation
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/name: frontegg-enterprise
        app.kubernetes.io/instance: xxx
        job-name: xxx-frontegg-enterprise-initdb
    spec:
      restartPolicy: Never
      containers:
      - name: mysql-client
        image: "mysql:8.0"
        imagePullPolicy: IfNotPresent
        # Add resource requests to help scheduling
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
        env:
        - name: MYSQL_HOST
          valueFrom:
            secretKeyRef:
              # Reference the k8s Secret created by identity-mysql-external-secret.yaml
              name: identity-mysql-credentials
              key: host
        - name: MYSQL_USER
          valueFrom:
            secretKeyRef:
              name: identity-mysql-credentials
              key: username
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: identity-mysql-credentials
              key: password
        command:
        - /bin/sh
        - -c
        - |
          echo "Waiting for DB host $MYSQL_HOST..."
          # Simple wait loop (adjust timeout/checks as needed)
          timeout=60
          while ! mysqladmin ping -h"$MYSQL_HOST" -u"$MYSQL_USER" -p"$MYSQL_PASSWORD" --silent; do
            timeout=$(($timeout - 1))
            if [ $timeout -eq 0 ]; then
              echo "Timeout waiting for DB."
              exit 1
            fi
            sleep 1
          done
          echo "DB host ready. Executing script..."
          mysql -h"$MYSQL_HOST" -u"$MYSQL_USER" -p"$MYSQL_PASSWORD" < /scripts/db.sql
          echo "Script execution finished."
        volumeMounts:
        - name: initdb-scripts
          mountPath: /scripts
      volumes:
      - name: initdb-scripts
        configMap:
          name: xxx-frontegg-enterprise-initdb-scripts
---
# Source: frontegg-enterprise/charts/admins/templates/secrets/external-secret.yaml
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: admins-v2
  annotations:
    argocd.argoproj.io/sync-options: Force=true,Replace=true
    argocd.argoproj.io/sync-wave: "-100"
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-delete-policy: before-hook-creation
    helm.sh/hook-weight: "-100"
  labels:
    helm.sh/chart: unified-chart-4.0.100
    app.frontegg.io/version: "4.0.100"
    app.frontegg.io/managed-by: Helm
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "0b5b99d"
spec:
  refreshInterval: 1m
  secretStoreRef:
    name: external-secret-store
    kind: ClusterSecretStore
  target:
    name: admins-v2
    template:
      engineVersion: v2
      data:
        config: |
          {{- $secret := .contents | fromYaml }}
          FRONTEGG_EVENT_SERVICE_API_KEY={{ $secret.frontegg.apiKeys.eventsServiceApiKey | toYaml }}
          FRONTEGG_ADMINS_SERVICE_API_KEY={{ $secret.frontegg.apiKeys.adminsServiceApiKey | toYaml }}
          FRONTEGG_VENDORS_SERVICE_API_KEY={{ $secret.frontegg.apiKeys.vendorsServiceApiKey | toYaml }}
          FRONTEGG_IDENTITY_SERVICE_API_KEY={{ $secret.frontegg.apiKeys.identityServiceApiKey | toYaml }}
          FRONTEGG_CLIENT_ID={{ $secret.frontegg.xxx.fronteggClientId | toYaml }}
          FRONTEGG_KAFKA_BROKER_LIST={{ $secret.databases.kafka.brokerList | toYaml }}
          FRONTEGG_KAFKA_SASL_PASSWORD={{ $secret.databases.kafka.saslPassword | toYaml }}
          FRONTEGG_KAFKA_SASL_USERNAME={{ $secret.databases.kafka.saslUserName | toYaml }}
          FRONTEGG_SPLIT_IO_KEY={{ $secret.externalServices.split.sdkKey | toYaml }}
          FRONTEGG_TENANTS_SERVICE_API_KEY={{ $secret.frontegg.apiKeys.tenantsServiceApiKey | toYaml }}
          
  data:
    - secretKey: contents
      remoteRef:
        conversionStrategy: Default	
        decodingStrategy: None
        key: prod-main-secret20250407120514343900000001
---
# Source: frontegg-enterprise/charts/oauth-service/templates/secrets/external-secret.yaml
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: oauth-v2
  annotations:
    argocd.argoproj.io/sync-options: Force=true,Replace=true
    argocd.argoproj.io/sync-wave: "-100"
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-delete-policy: before-hook-creation
    helm.sh/hook-weight: "-100"
  labels:
    helm.sh/chart: unified-chart-4.0.100
    app.frontegg.io/version: "4.0.100"
    app.frontegg.io/managed-by: Helm
    app.frontegg.com/team: frontegg
    app.frontegg.com/appVersion: "adb9c44"
spec:
  refreshInterval: 1m
  secretStoreRef:
    name: external-secret-store
    kind: ClusterSecretStore
  target:
    name: oauth-v2
    template:
      engineVersion: v2
      data:
        config: |
          {{- $secret := .contents | fromYaml}}
          apiKey: {{ $secret.frontegg.apiKeys.oauthServiceApiKey | toYaml }}
          fronteggClientId: {{ $secret.frontegg.xxx.fronteggClientId | toYaml }}
          splitIO:
            key: {{ $secret.externalServices.split.sdkKey | toYaml }}
            redis:
              host: {{ $secret.databases.redis.host | toYaml }}
              port: {{ $secret.databases.redis.port | toYaml }}
              password: {{ $secret.databases.redis.password | toYaml }}
          databases:
            mySql:
              host: {{ $secret.databases.generalMysql.host | toYaml }}
              username: {{ $secret.databases.generalMysql.username | toYaml }}
              password: {{ $secret.databases.generalMysql.password | toYaml }}
              ssl: {{ $secret.databases.generalMysql.useSsl | toYaml }}
          redis:
            host: {{ $secret.databases.redis.host | toYaml }}
            port: {{ $secret.databases.redis.port | toYaml }}
            password: {{ $secret.databases.redis.password | toYaml }}
            tls: {{ $secret.databases.redis.tls | toYaml }}
          cryptoKey: {{ $secret.frontegg.applications.oauth.oauthServiceCryptoKey | toYaml }}
          identityCryptoKey: {{ $secret.frontegg.applications.identity.cryptoKey | toYaml }}
          oauthServiceSigningKey: {{ $secret.frontegg.applications.oauth.oauthServiceSigningKey | toYaml }}
          internalServices:
            identity:
              apiKey: {{ $secret.frontegg.apiKeys.identityServiceApiKey | toYaml }}
            applications:
              apiKey: {{ $secret.frontegg.apiKeys.applicationsServiceApiKey | toYaml }}
            teamManagement:
              apiKey: {{ $secret.frontegg.apiKeys.teamManagementApiKey | toYaml }}
            tenantsService:
              apiKey: {{ $secret.frontegg.apiKeys.tenantsServiceApiKey | toYaml }}
            vendors:
              apiKey: {{ $secret.frontegg.apiKeys.vendorsServiceApiKey | toYaml }}
          kafka:
            brokerList: {{ $secret.databases.kafka.brokerList | toYaml }}
            saslPassword: {{ $secret.databases.kafka.saslPassword | toYaml }}
            saslUsername: {{ $secret.databases.kafka.saslUserName | toYaml }}
          
  data:
    - secretKey: contents
      remoteRef:
        conversionStrategy: Default	
        decodingStrategy: None
        key: prod-main-secret20250407120514343900000001
---
# Source: frontegg-enterprise/templates/identity-mysql-external-secret.yaml
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: identitymysql-secret
  annotations:
    "helm.sh/hook": pre-install, pre-upgrade
    "helm.sh/hook-weight": "-20"
spec:
  refreshInterval: "1h"
  secretStoreRef:
    name: external-secret-store
    kind: ClusterSecretStore
  target:
    name: identity-mysql-credentials
    creationPolicy: Owner
    template:
      engineVersion: v2
      data: 
        host: |      
          {{ $secret := .raw_yaml  | fromYaml }} 
          {{- $secret.databases.identityMysql.host -}}
        username: |
          {{ $secret := .raw_yaml  | fromYaml }} 
          {{- $secret.databases.identityMysql.username -}}
        password: |
          {{ $secret := .raw_yaml  | fromYaml }}
          {{- $secret.databases.identityMysql.password -}}
        useSsl: |
          {{ $secret := .raw_yaml  | fromYaml }} 
          {{- $secret.databases.identityMysql.useSsl -}}
  data:
    - secretKey: raw_yaml
      remoteRef:
        key: prod-main-secret20250407120514343900000001
